brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state) %>% summarise(tetanus_ = sum(!is.na(tetanus)),hivtest=sum(!is.na(hivtst6)), pneumonia=sum(!is.na(pneuvac3)), flushot = sum(!is.na(flushot6)))
brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state) %>% summarise(tetanus_ = count(!is.na(tetanus)),hivtest=count(!is.na(hivtst6)), pneumonia=count(!is.na(pneuvac3)), flushot = count(!is.na(flushot6)))
posdata <- brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state)
posdata
posdata %>% group_by(pneuvac3) %>% summarise(count=n())
posdata %>% group_by(pneuvac3) %>% summarise(sum(!is.na(pneuvac3))
;
posdata %>% group_by(pneuvac3) %>% summarise(sum(!is.na(pneuvac3)))
brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state) %>% summarise(tetanus_ = count(!is.na(tetanus)),hivtest=count(!is.na(hivtst6)), pneumonia=count(!is.na(pneuvac3)), flushot = count(!is.na(flushot6)))
brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state) %>% summarise(tetanus_ = sum(!is.na(tetanus)),hivtest=sum(!is.na(hivtst6)), pneumonia=sum(!is.na(pneuvac3)), flushot = sum(!is.na(flushot6)))
brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state) %>% summarise(count =n())
ggplot(posdata, aes(x= X_state,y=count))+geom_point()+theme(axis.text.x = element_text(angle = 90))
ggplot(posdata, aes(x= X_state)+geom_histogram()
;
ggplot(posdata, aes(x= X_state))+geom_histogram()
posdata
posdata <- brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state) %>% summarise(sum(!is.na(pneuvac3)))
posdata
posdata <- brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state) %>% summarise(val = sum(!is.na(pneuvac3)))
ggplot(posdata, aes(x = X_state,y = val)+geom_point()+theme(axis.text.x = element_text(angle = 90))
;
ggplot(posdata, aes(x = X_state,y = val)+geom_point()+theme(axis.text.x = element_text(angle = 90)))
ggplot(posdata, aes(x = X_state,y = val))+geom_point()+theme(axis.text.x = element_text(angle = 90))
View(posdata)
posdata -> brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state) %>% summarise(val = sum(!is.na(pneuvac3))) %>% arrange(val)
posdata <- brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state) %>% summarise(val = sum(!is.na(pneuvac3))) %>% arrange(val)
ggplot(posdata, aes(x = X_state,y = val))+geom_point()+theme(axis.text.x = element_text(angle = 90))
posdata <- brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state) %>% summarise(val = sum(!is.na(pneuvac3))) %>% arrange(val)
load("C:/Users/minma/OneDrive/statswithR/INtro_to_data_and_R/Project/brfss2013.RData")
load
library('dplyr')
library(ggplot2)
posdata <- brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state) %>% summarise(val = sum(!is.na(pneuvac3))) %>% arrange(val)
posdata
brfss2013 %>% select(X_state,pneuvac3,hivtst6,flushot6,tetanus) %>% filter(tetanus!= 'No, did not receive any tetanus since 2005',pneuvac3 !='No',flushot6!= 'No',hivtst6!='No' ) %>% group_by(X_state) %>% summarise(val = sum(!is.na(pneuvac3))) %>% arrange(desc(val))
ggplot(posdata, aes(x = X_state,y = val))+geom_point()+theme(axis.text.x = element_text(angle = 90))
ggplot(posdata, aes(x = X_state,y = val))+geom_point()+theme(axis.text.x = element_text(angle = 45))
ggplot(posdata, aes(x = X_state,y = val))+geom_point()+theme(axis.text.x = element_text(angle = 75))
ggplot(posdata, aes(x = X_state,y = val))+geom_point()+theme(axis.text.x = element_text(angle = 85))
ggplot(posdata, aes(x = X_state,y = val))+geom_point()+theme(axis.text.x = element_text(angle = 90))
ggplot(posdata, aes(x = X_state,y = val))+geom_point()+theme(axis.text.x = element_text(angle = 99))
ggplot(posdata, aes(x = X_state,y = val))+geom_point()+theme(axis.text.x = element_text(angle = 94))
ggplot(posdata, aes(x = X_state,y = val))+geom_point()+theme(axis.text.x = element_text(angle = 97))
View(brfss2013)
summary(gss)
load("gss.Rdata")
library(devtools)
library(dplyr)
install_github(StatswithR/statsr)
install_github(StatsWithR/statsr)
install_github("StatsWithR/statsr")
detach(dplyr)
detach("dplyr",character.only = TRUE)
detach_package(dplyr)
?detach
require(dplyr)
detach(package:dplyr)
install_github("StatsWithR/statsr")
require(statsr)
detach(stats)
detach(statsr)
detach(package:statsr)
install_github("StatsWithR/statsr")
library(dplyr)
library(ggplot2)
library(statsr)
library(GGally)
load(evals)
load("evals")
data(evals)
force(evals)
m_bty <- lm(data=evals, score~bty_avg)
summary(m_bty)
m_bty_gender <- lm(data=evals, score ~ bty_avg+gender)
summary(bty_gender)
summary(m_bty_gen)
summary(m_bty_gender)
m_bty_rank <- lm(evals, score ~ bty_avg + rank)
m_bty_rank <- lm(data=evals, score ~ bty_avg + rank)
summary(m_bty_rank)
ggplot(data=evals,aes(x=bty_avg,y=score, group=rank, colour=rank))+geom_jitter(size = 1, fill="white")+stat_smooth(method="lm")
ggplot(data=evals,aes(x=bty_avg,y=score, group=rank, colour=rank))+geom_jitter(size = 1, fill="white")+stat_smooth(method="lm",se=FALSE)
evals %>% group_by(rank) %>% summarise(MEAN =mean(score)) %>% arrange(mean)
evals %>% group_by(rank) %>% summarise(MEAN=mean(score)) %>% arrange(mean)
evals %>% group_by(rank) %>% summarise(MEAN=mean(score)
)
evals %>% group_by(rank) %>% summarise(MEAN=mean(score)) %>% arrange(mean)
evals %>% group_by(rank) %>% summarise(MEAN=mean(score)) %>% arrange(MEAN)
MEAN
evals %>% group_by(rank) %>% summarise(MEAN=mean(score)) %>% arrange(MEAN)
library(ggplot2)
library(dplyr)
library(statsr)
load(movies.Rdata)
View(brfss2013)
load("movies.Rdata'")
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
install.packages(tinytex\)
/
install.packages(tinytex)
install.packages(tinytex'')
install.packages('tinytex')
install.packages('xfun')
install.packages("xfun")
install.packages("xfun")
library(statsr)
library(tidyverse)
q()
install.packages("tidyverse")
install.packages("statsr")
qbeta(c(0.025,0.975),shape1 = 50,shape2 = 50)
qbeta(c(0.025,0.975),shape1 = 1,shape2 = 1)
pbeta
qbta
qbeta
pbeta(0.2,1+3,24+1-3)
```{r q10}
pstar<-(1/6)*(8/10)/((1/6)*(8/10)+1*2/10) #post probability that coin is fair
p6post<-pstar*1/6+(1-pstar)*1
p6post
```
pstar<-(1/6)*(8/10)/((1/6)*(8/10)+1*2/10)
p6post<-pstar*1/6+(1-pstar)*1
p6post
install.packages("tidyverse")
install.packages('PairedData')
install.packages('dplyr')
install.packages('ggplot2')
library(statsr)
library(PairedData)
library(ggplot2)
library(dplyr)
version
install.packages('installr)
''
;
'
install.packages('installr')
library(installr)
updateR()
updateR()
updateR()
setwd("E:/badadata/files/Udemy_Machine_Learning/udemy_ML_R/9 Dimensionality Reduction/Principal Component Analysis")
dataset = read.csv('Wine.csv')
##TRAIN_TEST_SPLIT
library(caTools)
set.seed(121)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split = TRUE)
test_set = subset(dataset,split = FALSE)
dataset = read.csv('Wine.csv')
##TRAIN_TEST_SPLIT
library(caTools)
set.seed(121)
split = sample.split(dataset$Customer_Segment, SplitRatio = 0.75)
training_set = subset(dataset, split = TRUE)
test_set = subset(dataset,split = FALSE)
View(dataset)
View(training_set)
View(test_set)
##FEATURE SCALING
training_set[-14] = scale(training_set[-14])
test_set[-14] = scale(test_set[-14])
library(caret)
library(e1071)
training_set = predict(pca, training_set)
pca = preProcess(x = training_set[-14],
method = pca,
pcaComp = 2)
training_set = predict(pca, training_set)
pca = preProcess(x = training_set[-14],
method = "pca",
pcaComp = 2)
training_set = predict(pca, training_set)
training_set = training_set[c(2:3,1)]
test_set = predict(pca, test_set)
test_set = test_set[c(2,3,1)]
##LOGISTIC REGRESSION MODEL FIT
classifier = glm(formula = Customer_segment ~ .,
family = binomial,
data = training_set)
###Predicting Test Set results.
probability_pred = predict(classifier, type = 'response',
newdata = test_set[-14])
y_pred = ifelse(probability_pred > 0.5 , 1, 0)
###Confusion Matrix
cm = table(test_set[,14], y_pred)
##Visualize Train set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
install.packages('ElemStatLearn')
install.packages("E:/badadata/files/ElemStatLearn_2015.6.26.2.tar.gz", repos = NULL, type = "source")
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Principal Component Analysis
dataset = read.csv('Wine.csv')
##TRAIN_TEST_SPLIT
library(caTools)
set.seed(121)
split = sample.split(dataset$Customer_Segment, SplitRatio = 0.75)
training_set = subset(dataset, split = TRUE)
test_set = subset(dataset,split = FALSE)
##FEATURE SCALING
training_set[-14] = scale(training_set[-14])
test_set[-14] = scale(test_set[-14])
#Applying PCA
library(caret)
library(e1071)
pca = preProcess(x = training_set[-14],
method = "pca",
pcaComp = 2)
training_set = predict(pca, training_set)
training_set = training_set[c(2:3,1)]
test_set = predict(pca, test_set)
test_set = test_set[c(2:3,1)]
##LOGISTIC REGRESSION MODEL FIT
classifier = glm(formula = Customer_segment ~ .,
family = binomial,
data = training_set)
###Predicting Test Set results.
probability_pred = predict(classifier, type = 'response',
newdata = test_set[-14])
y_pred = ifelse(probability_pred > 0.5 , 1, 0)
###Confusion Matrix
cm = table(test_set[,14], y_pred)
##Visualize Train set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Principal Component Analysis
dataset = read.csv('Wine.csv')
##TRAIN_TEST_SPLIT
library(caTools)
set.seed(121)
split = sample.split(dataset$Customer_Segment, SplitRatio = 0.75)
training_set = subset(dataset, split = TRUE)
test_set = subset(dataset,split = FALSE)
##FEATURE SCALING
training_set[-14] = scale(training_set[-14])
test_set[-14] = scale(test_set[-14])
#Applying PCA
library(caret)
library(e1071)
pca = preProcess(x = training_set[-14],
method = "pca",
pcaComp = 2)
training_set = predict(pca, training_set)
training_set = training_set[c(2:3,1)]
test_set = predict(pca, test_set)
test_set = test_set[c(2:3,1)]
##LOGISTIC REGRESSION MODEL FIT
classifier = glm(formula = Customer_Segment ~ .,
family = binomial,
data = training_set)
###Predicting Test Set results.
probability_pred = predict(classifier, type = 'response',
newdata = test_set[-14])
y_pred = ifelse(probability_pred > 0.5 , 1, 0)
###Confusion Matrix
cm = table(test_set[,14], y_pred)
##Visualize Train set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
classifier = glm(formula = Customer_Segment ~ .,
family = binomial,
data = training_set)
#apply svm
classifier = svm(formula = Customer_Segment ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-3])
# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
# Visualising the Training set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3], main = 'SVM (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
cm
# Visualising the Training set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM (Training set)',
xlab = 'PC1', ylab = 'PC2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue',
ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3',
ifelse(set[, 3] == 1, 'green4', 'red3')))
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('PC1', 'PC2')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3], main = 'SVM (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue',
ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3',
ifelse(set[, 3] == 1, 'green4', 'red3')))
# Principal Component Analysis
dataset = read.csv('Wine.csv')
##TRAIN_TEST_SPLIT
library(caTools)
set.seed(121)
split = sample.split(dataset$Customer_Segment, SplitRatio = 0.75)
training_set = subset(dataset, split = TRUE)
test_set = subset(dataset,split = FALSE)
##FEATURE SCALING
training_set[-14] = scale(training_set[-14])
test_set[-14] = scale(test_set[-14])
#Applying PCA
library(caret)
library(e1071)
pca = preProcess(x = training_set[-14],
method = "pca",
pcaComp = 2)
training_set = predict(pca, training_set)
training_set = training_set[c(2:3,1)]
test_set = predict(pca, test_set)
test_set = test_set[c(2:3,1)]
#apply svm
classifier = svm(formula = Customer_Segment ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-3])
# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
# Visualizing the Training set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('PC1', 'PC2')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM (Training set)',
xlab = 'PC1', ylab = 'PC2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue',
ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3',
ifelse(set[, 3] == 1, 'green4', 'red3')))
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('PC1', 'PC2')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3], main = 'SVM (Test set)',
xlab = 'PC1', ylab = 'PC2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue',
ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3',
ifelse(set[, 3] == 1, 'green4', 'red3')))
